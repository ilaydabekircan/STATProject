---
title: "Untitled"
format: html
editor: visual
---

```{r}
library(tidyverse)
library(ggplot2)
```

```{r}
data.bank <- read.csv("/Users/ilaydabekircan/Documents/STAT/Project/BankChurners.csv")
data.bank
```

```{r}
summary(data.bank)
```

```{r}
sum(is.na(data.bank))

```

```{r}
# Dropping the CLIENTNUM column using Base R
data.bank <- data.bank[, -which(names(data.bank) == "CLIENTNUM")]
# Dropping the last two columns
data.bank <- data.bank[, -c((ncol(data.bank)-1), ncol(data.bank))]
summary(data.bank)
```

```{r}
(correlation_matrix <- cor(data.bank[sapply(data.bank, is.numeric)]))
```

```{r}
#correlation between Credit_Limit and Avg_Open_To_Buy
print(correlation_matrix[9, "Credit_Limit"])
```

Extremely high correlation between predictors can cause multicollinearity, making it challenging for the regression model to estimate unique coefficients for each predictor. Also, multicollinearity can lead to inflated standard errors for the coefficients, making the estimation less precise. Therefore, we drop the column 'Avg_Open_To_Buy' to reduce instability.

**Note to Victoria: If we don't drop this column, logit model gives na values for Avg_Open_To_Buy and vif cannot be calculated, it gives an error saying that there is a perfect correlation between two predictors.**

```{r}
data.bank <- data.bank[, -which(names(data.bank) == "Avg_Open_To_Buy")]
```

```{r}
data.bank$Attrition_Flag <- as.factor(ifelse(data.bank$Attrition_Flag == "Existing Customer", 0, 1))
table(data.bank$Attrition_Flag)
```

```{r}

data.bank$Gender <- as.factor(data.bank$Gender)
data.bank$Education_Level <- as.factor(data.bank$Education_Level)
data.bank$Marital_Status <- as.factor(data.bank$Marital_Status)
data.bank$Income_Category <- as.factor(data.bank$Income_Category)
data.bank$Card_Category <- as.factor(data.bank$Card_Category)

str(data.bank)

```

```{r}

# Bar chart comparing the counts of Education Level within each Marital Status category
ggplot(data.bank, aes(x = Education_Level, fill = Marital_Status)) +
  geom_bar(position = "dodge") +
  labs(x = "Education Level", y = "Count", fill = "Marital Status") +
  theme_minimal()

```

```{r}
# Boxplot comparing Customer Age across different Education Levels
ggplot(data.bank, aes(x = Education_Level, y = Customer_Age, fill = Education_Level)) +
  geom_boxplot() +
  labs(x = "Education Level", y = "Customer Age") +
  theme_minimal()

```

```{r}
ggplot(data.bank, aes(x = Income_Category, y = Customer_Age, fill = Income_Category)) +
  geom_boxplot() +
  labs(x = "Income Category", y = "Customer Age") +
  theme_minimal()
```

```{r}
ggplot(data.bank, aes(x = Customer_Age)) +
  geom_histogram(bins = 30, fill = "blue", color = "white") +
  labs(x = "Customer Age", y = "Frequency") +
  theme_minimal()
```

```{r}
ggplot(data.bank, aes(x = Credit_Limit, fill = Gender)) +
  geom_density(alpha = 0.7) +
  labs(x = "Credit Limit", y = "Density", fill = "Gender") +
  theme_minimal()
```

```{r}
ggplot(data.bank, aes(x = Attrition_Flag)) +
  geom_bar(aes(fill = Attrition_Flag)) +
  labs(x = "Attrition Flag", y = "Count", fill = "Attrition Status") +
  theme_minimal()
```

```{r}
# Scatter Plot of Total Transactions vs. Credit Limit
ggplot(data.bank, aes(x = Total_Trans_Amt, y = Credit_Limit, color = Attrition_Flag)) +
  geom_point(alpha = 0.6) +
  labs(x = "Total Transactions Amount", y = "Credit Limit", color = "Attrition Flag") +
  theme_minimal()
```

```{r}
# setting seed before splitting train and test sets
set.seed(1)
ratio <- 0.80
train_set <- sort(sample(1:nrow(data.bank), ceiling(nrow(data.bank)*ratio)))

# creating train and test set
data.train <- data.bank[train_set, ]
data.test  <- data.bank[-train_set, ]
```

```{r}
# 0 and 1 ratio of data, train and test
(summary(data.bank$Attrition_Flag) / nrow(data.bank))
(summary(data.train$Attrition_Flag) / nrow(data.train))
(summary(data.test$Attrition_Flag) / nrow(data.test))
```

```{r}
logit.null <- glm(Attrition_Flag ~ 1, 
                  data = data.train, 
                  family = binomial(link = "logit"))
summary(logit.null)
```

```{r}
library(caret)
```

```{r}
pred.logit_null <- predict(logit.null, newdata = data.test, type="response")

condition.logit_null <- ifelse(pred.logit_null > 0.5, 1, 0)
(confusion_matrix.logit_null <- confusionMatrix(reference = as.factor(data.test$Attrition_Flag), 
                                                data = as.factor(condition.logit_null), 
                                                mode="everything"))
```

```{r}
library(pROC)
auc(data.test$Attrition_Flag, pred.logit_null)
```

```{r}
logit.full <- glm(Attrition_Flag ~ ., 
                  data = data.train, 
                  family = binomial(link = "logit"))
summary(logit.full)
```

```{r}
pred.logit_full <- predict(logit.full, newdata = data.test, type="response")

condition.logit_full <- ifelse(pred.logit_full > 0.5, 1, 0)
(confusion_matrix.logit_full <- confusionMatrix(reference = as.factor(data.test$Attrition_Flag), 
                                                data = as.factor(condition.logit_full), 
                                                mode="everything"))
```

```{r}
auc(data.test$Attrition_Flag, pred.logit_full)
```

```{r}
car::vif(logit.full)
```

```{r}
logit.both <- step(logit.null, list(lower=formula(logit.null),
                                    upper=formula(logit.full)),
                                    direction="both",
                                    trace=0, 
                                    data = data.train)
summary(logit.both)
```

```{r}
pred.logit_both <- predict(logit.both, newdata = data.test, type="response")

condition.logit_both <- ifelse(pred.logit_both > 0.5, 1, 0)
(confusion_matrix.logit_both <- confusionMatrix(reference = as.factor(data.test$Attrition_Flag), 
                                                data = as.factor(condition.logit_both), 
                                                mode="everything"))
```

```{r}
auc(data.test$Attrition_Flag, pred.logit_both)
```

| Model Metrics     | Full Logit Model | Reduced Logit Model |
|-------------------|------------------|---------------------|
| Residual Deviance | 3737.3           | 3747.8              |
| AIC               | 3801.3           | 3793.8              |
| Accuracy          | 89.73%           | 89.73%              |
| Sensitivity       | 96.17%           | 95.99%              |
| Specificity       | 56.67%           | 57.58%              |
| AUC               | 0.9219           | 0.9215              |

-   Add deviance residual plots for null, full and reduced logit
-   Outliers, leverage points, cooks distance, dffits
