---
title: "Statistical Analysis of Customer Credit Card Attrition"
author: "Victoria Agboola, Ilayda Bekircan"
format: pdf
editor: visual
---

## ABSTRACT

## INTRODUCTION

In the fast-paced environment of finance and banking industries, customer attrition threatens business managers and companies seeking to maintain a healthy business relationship with their customers. As financial institutions aims to follow market trends and consumer behaviors, to understand and predict credit card attrition becomes increasingly important. Recently, population of newly credit card customers has shrunk in an important scale. Therefore, banks are forced to have different and brilliant strategies to attract new customers from other financial institutions to improve their portfolio. To attract more new customers, banks strategize lower interest rates in credit cards for a time period at the beginning. However, when this advantageous period ends, customers tend to transfer their balance to an another bank before the interest rate pivots to the default value. Consequently, rather than maintaining existing customers, attracting new customers becomes more and more costly for the institutions. Banks set a course for managing their existing customers not to leave their credit card products since it cost less to invest on them. Accordingly, portfolio of existing customers are prone to increase their spendings on their credit cards more \[1\].

The significance of anticipating which clients, particularly those with a high return on investment, are prone to leaving has grown in importance for banks. Focusing on this foresight, financial institutions can implement targeted marketing initiatives that have demonstrated efficiency in customer retention. Given the elevated importance and widespread interest among financial entities, this project introduces machine learning methodologies for classifying credit card attrition \[2\].

An increasing rate of customer attrition causes unsettling problems for the company with a consumer credit card portfolio. Managers and data analytics teams must answer important questions while clients stop using the bank's credit card services: What causes this attrition and what motivates it? Are there any trends that causes customers stop using their credit cards? How can this information be properly used to forecast and stop attrition? It is essential to minimize financial losses to build client loyalty and improve business sustainability by comprehending the analysis of credit card attrition. The bank can implement strategies to retain valuable customers and improve customer engagement procedures by resolving root causes of customer churn. In order to provide business managers with useful insights, this project uses extensive statistical methods to comb through the complexity of customer attrition in the banking industry and identify the underlying causes.

The primary goal of this project is to conduct a comprehensive statistical analysis of credit card attrition of customers in a bank's portfolio. The project aims to reveal trends and root causes that originates customer attrition by developing predictive models including binary logit, CART (Classification and Regression Trees), Random Forest, and XGBoost to forecast customer churn with enhanced accuracy. By leveraging machine learning algorithms, we seek to understand the reasons behind driving customer attrition in banks. This predictive capability will equip the business managers with valuable insights, enabling them to implement targeted retention strategies and mitigate potential financial losses.

## DATA DESCRIPTION

**Attrition_Flag:** This variable is the binary response variable which refers if a customer's account is closed or not. If a credit card is not in use anymore, this variable is flagged as "Attrited Customer" and if it is still in use, it is flagged as "Existing Customer". This variable will be converted to 0 for existing customers and 1 for attrited customers for easy interpretation and simple usage in machine learning models. The data set consists of 84% of existing customers and 16% of attrited customers.

The following parameters will be used as independent variables (predictors) in the machine learning models you will see in the following parts of the project.

**Customer_Age:** This variable represents age of account holders in the bank's portfolio. The unit of this variable is years. The minimum and maximum age in this data set are 26 and 73, respectively. The frequency of occurence is at high point between ages 40 and 50.

**Gender:** This is the sex of the account holders which gives us information about the demographic structure of the population in the data set. 53% of the observations are constructed by females while 47% of them are by males. Since the percentages are close to each other, we can assume gender distribution is balanced.

**Dependent_count:** This variable shows how many other individuals are considered as dependent for the corresponding customer. If a customer has no dependent individual in their financial account, this parameter is labeled as 0. The maximum number of dependent individuals in this data set is 5.

**Education_Level:** This parameter represents seven different education level status for the customers in the portfolio. The distinct values are Uneducated, High School, College, Graduate, Post-Graduate, Doctorate and Unknown.

**Marital_Status:** This predictor involves four unique marital status: Divorced, Marries, Single and Unknown.

**Income_Category:** This is an independet variable that gives information about the account holders' annual incomes in categories: Less than \$40K, \$40K - \$60K, \$60K - \$80K, \$80K - \$120K, \$120K+ and Unknown.

**Card_Category:** The bank has different credit card types that each one has different benefits. There are four unique products Blue, Gold, Platinum, Silver and 93.18% of the observations have Blue card in the data set.

**Months_on_book:** This one represents the period of relationship of the client to their credit cards in months. The minimum months on book is 13 while the maximum amount in the data set is 56.

**Total_Relationship_Count:** Total relationship count shows the total number of products that the corresponding customer holds in the bank. Since all customers have at least one product in the data set, the minimum amount is always 1 which can increase up to 6.

**Months_Inactive_12_mon:** If a customer has any inactivity for a whole month in the last 12 months, this parameter gives the total number of inactive month number. If there is no inactivity for a whole year, it gives 0.

**Contacts_Count_12_mon:** This predictor is the contact number between the customer and the bank in the last 12 months. This number can differ from 0 to 6.

**Credit_Limit:** This gives the credit card limit of the client in dollars (\$). The range is between \$1438 and \$34,516.

**Total_Revolving_Bal:** Reveolving balance is the balance carries over from one month to the next and this predictor gives the information in dollars (\$). If a customer pays their checks in time, the total revolving balance is 0.

**Avg_Open_To_Buy:** Open to buy means the amount left in the customer's credit card that they can use montly. This parameter (Average open to buy) gives the average of open to buy values of last 12 months in dollars (\$).

**Total_Trans_Amt:** Total transaction amount is the sum of all the transactions happening in the customer's account in the last 12 months in dollars (\$).

**Total_Trans_Ct:** Total transaction count is the count of all the transactions happening in the customer's account in the last 12 months.

**Total_Ct_Chng_Q4_Q1:** This variable gives information about the ratio of the total transaction count in 4th quarter to the total transaction count in 1st quarter.

**Total_Amt_Chng_Q4_Q1:** This is the ratio of the total transaction amount in 4th quarter to the total transaction amount in 1st quarter.

**Avg_Utilization_Ratio:** Average utilization ratio represents how much of the available credit the customer spent by their credit cards.

## GOAL

## STATISTICAL METHODS

## RESULTS

```{r}
library(tidyverse)
library(ggplot2)
```

```{r}
data.bank <- read.csv("/Users/ilaydabekircan/Documents/STAT/Project/BankChurners.csv")
```

```{r}
summary(data.bank)
```

```{r}
sum(is.na(data.bank))

```

```{r}
# Dropping the CLIENTNUM column using Base R
data.bank <- data.bank[, -which(names(data.bank) == "CLIENTNUM")]
# Dropping the last two columns
data.bank <- data.bank[, -c((ncol(data.bank)-1), ncol(data.bank))]
summary(data.bank)
```

```{r}
(correlation_matrix <- cor(data.bank[sapply(data.bank, is.numeric)]))
```

```{r}
#correlation between Credit_Limit and Avg_Open_To_Buy
print(correlation_matrix[9, "Credit_Limit"])
```

Extremely high correlation between predictors can cause multicollinearity, making it challenging for the regression model to estimate unique coefficients for each predictor. Also, multicollinearity can lead to inflated standard errors for the coefficients, making the estimation less precise. Therefore, we drop the column 'Avg_Open_To_Buy' to reduce instability.

```{r}
data.bank <- data.bank[, -which(names(data.bank) == "Avg_Open_To_Buy")]
```

```{r}
data.bank$Attrition_Flag <- as.factor(ifelse(data.bank$Attrition_Flag == "Existing Customer", 0, 1))
table(data.bank$Attrition_Flag)
```

```{r}

data.bank$Gender <- as.factor(data.bank$Gender)
data.bank$Education_Level <- as.factor(data.bank$Education_Level)
data.bank$Marital_Status <- as.factor(data.bank$Marital_Status)
data.bank$Income_Category <- as.factor(data.bank$Income_Category)
data.bank$Card_Category <- as.factor(data.bank$Card_Category)

str(data.bank)

```

```{r}

# Bar chart comparing the counts of Education Level within each Marital Status category
ggplot(data.bank, aes(x = Education_Level, fill = Marital_Status)) +
  geom_bar(position = "dodge") +
  labs(x = "Education Level", y = "Count", fill = "Marital Status") +
  theme_minimal()

```

```{r}
# Boxplot comparing Customer Age across different Education Levels
ggplot(data.bank, aes(x = Education_Level, y = Customer_Age, fill = Education_Level)) +
  geom_boxplot() +
  labs(x = "Education Level", y = "Customer Age") +
  theme_minimal()

```

```{r}
ggplot(data.bank, aes(x = Income_Category, y = Customer_Age, fill = Income_Category)) +
  geom_boxplot() +
  labs(x = "Income Category", y = "Customer Age") +
  theme_minimal()
```

```{r}
ggplot(data.bank, aes(x = Customer_Age)) +
  geom_histogram(bins = 30, fill = "blue", color = "white") +
  labs(x = "Customer Age", y = "Frequency") +
  theme_minimal()
```

```{r}
ggplot(data.bank, aes(x = Credit_Limit, fill = Gender)) +
  geom_density(alpha = 0.7) +
  labs(x = "Credit Limit", y = "Density", fill = "Gender") +
  theme_minimal()
```

```{r}
ggplot(data.bank, aes(x = Attrition_Flag)) +
  geom_bar(aes(fill = Attrition_Flag)) +
  labs(x = "Attrition Flag", y = "Count", fill = "Attrition Status") +
  theme_minimal()
```

```{r}
# Scatter Plot of Total Transactions vs. Credit Limit
ggplot(data.bank, aes(x = Total_Trans_Amt, y = Credit_Limit, color = Attrition_Flag)) +
  geom_point(alpha = 0.6) +
  labs(x = "Total Transactions Amount", y = "Credit Limit", color = "Attrition Flag") +
  theme_minimal()
```

```{r}
# setting seed before splitting train and test sets
set.seed(42)
ratio <- 0.80
train_set <- sort(sample(1:nrow(data.bank), ceiling(nrow(data.bank)*ratio)))

# creating train and test set
data.train <- data.bank[train_set, ]
data.test  <- data.bank[-train_set, ]
```

```{r}
# 0 and 1 ratio of data, train and test
(summary(data.bank$Attrition_Flag) / nrow(data.bank))
(summary(data.train$Attrition_Flag) / nrow(data.train))
(summary(data.test$Attrition_Flag) / nrow(data.test))
```

```{r}
logit.null <- glm(Attrition_Flag ~ 1, 
                  data = data.train, 
                  family = binomial(link = "logit"))
summary(logit.null)
```

```{r}
library(caret)
```

```{r}
pred.logit_null <- predict(logit.null, newdata = data.test, type="response")

condition.logit_null <- ifelse(pred.logit_null > 0.5, 1, 0)
(confusion_matrix.logit_null <- confusionMatrix(reference = as.factor(data.test$Attrition_Flag), 
                                                data = as.factor(condition.logit_null), 
                                                positive = "1",
                                                mode="everything"))
```

```{r}
library(pROC)
auc(data.test$Attrition_Flag, pred.logit_null)
```

```{r}
logit.full <- glm(Attrition_Flag ~ ., 
                  data = data.train, 
                  family = binomial(link = "logit"))
summary(logit.full)
```

```{r}
pred.logit_full <- predict(logit.full, newdata = data.test, type="response")

condition.logit_full <- ifelse(pred.logit_full > 0.5, 1, 0)
(confusion_matrix.logit_full <- confusionMatrix(reference = as.factor(data.test$Attrition_Flag), 
                                                data = as.factor(condition.logit_full), 
                                                positive = "1",
                                                mode="everything"))
```

```{r}
auc(data.test$Attrition_Flag, pred.logit_full)
```

```{r}
car::vif(logit.full)
```

```{r}
logit.both <- step(logit.null, list(lower=formula(logit.null),
                                    upper=formula(logit.full)),
                                    direction="both",
                                    trace=0, 
                                    data = data.train)
summary(logit.both)
```

```{r}
pred.logit_both <- predict(logit.both, newdata = data.test, type="response")

condition.logit_both <- ifelse(pred.logit_both > 0.5, 1, 0)
(confusion_matrix.logit_both <- confusionMatrix(reference = as.factor(data.test$Attrition_Flag), 
                                                data = as.factor(condition.logit_both), 
                                                positive = "1",
                                                mode="everything"))
```

```{r}
auc(data.test$Attrition_Flag, pred.logit_both)
```

| Model Metrics     | Full Logit Model | Reduced Logit Model |
|-------------------|------------------|---------------------|
| Residual Deviance | 3737.3           | 3747.8              |
| AIC               | 3801.3           | 3793.8              |
| Accuracy          | 89.73%           | 89.73%              |
| Sensitivity       | 96.17%           | 95.99%              |
| Specificity       | 56.67%           | 57.58%              |
| AUC               | 0.9219           | 0.9215              |

-   Add deviance residual plots for null, full and reduced logit
-   Outliers, leverage points, cooks distance, dffits

**Residual Diagnostic Plots**

```{r}
par(mfrow=c(2,2))
plot(logit.full)
```

```{r}
outliers <- which(abs(residuals(logit.full)) > 3*sd(residuals(logit.full)))

```

```{r}
data.train.2 <- data.train[-outliers,]
```

**Checking for high leverage cases**

```{r}
n <- nrow(data.train.2)
p <- ncol(data.train.2)-1
chilev <- which(influence(logit.full)$hat > max(2*(p+1)/n, 0.5))
chilev
```

**Checking for high influential points**

```{r}
cooksD <- cooks.distance(logit.full)
highCooksD <- which(cooksD > (4/(n-p-1)))
```

```{r}
data.train.3 <- data.train.2[-highCooksD,]
logit.full.2 <- glm(Attrition_Flag ~ ., 
                  data = data.train.3, 
                  family = binomial(link = "logit"))
summary(logit.full.2)

```

```{r}
par(mfrow=c(2,2))
plot(logit.full.2)
```

```{r}

pred.logit_full.2 <- predict(logit.full.2, newdata = data.test, type="response")

condition.logit_full.2 <- ifelse(pred.logit_full.2 > 0.5, 1, 0)
(confusion_matrix.logit_full.2 <- confusionMatrix(reference = as.factor(data.test$Attrition_Flag), 
                                                data = as.factor(condition.logit_full.2), 
                                                positive = "1",
                                                mode="everything"))
```

**explore interaction or transformation**

### Decision Tree

```{r}
library(rpart)
```

```{r}
fit.allpred <- rpart(Attrition_Flag ~., method = "class", data = data.train,
                  control = rpart.control(minsplit = 1, cp = 0.001))
```

```{r}
printcp(fit.allpred) 
```

```{r}
(cp= fit.allpred$cptable[which.min(fit.allpred$cptable[, "xerror"]), "CP"])
(xerr = fit.allpred$cptable[which.min(fit.allpred$cptable[, "xerror"]), "xerror"])
```

```{r}
plotcp(fit.allpred)
```

```{r}
library(rpart.plot)
```

```{r}
rpart.plot(fit.allpred, extra = "auto")
```

```{r}
test_df <- data.frame(actual = data.test$Attrition_Flag, pred = NA)
test_df$pred <- predict(fit.allpred, newdata = data.test, type = "class")
# Create the confusion matrix using caret
conf_matrix <- confusionMatrix(as.factor(test_df$pred), as.factor(test_df$actual), positive = "1")
conf_matrix
```

**Pruning Tree**

```{r}

prunefit.allp <- prune(fit.allpred, cp =
    fit.allpred$cptable[which.min(fit.allpred$cptable[, "xerror"]), "CP"])
```

```{r}
rpart.plot(prunefit.allp, extra = "auto")
```

```{r}
#summary(prunefit.allp)
```

The error rate computed on the training sample is

```{r}
rootnode_err <- sum(data.train$Attrition_Flag==1)/nrow(data.train)
prelerr = prunefit.allp$cptable[which.min(prunefit.allp$cptable[, "rel error"]), "rel error"]
(presub.err_rate <- rootnode_err*prelerr) 
```

error rate computed on the test sample is

```{r}
rootnode_err <- sum(data.train$Attrition_Flag==1)/nrow(data.train)
pxerr = prunefit.allp$cptable[which.min(prunefit.allp$cptable[, "xerror"]), "xerror"]
(pcv.err_rate <- rootnode_err*pxerr)
```

```{r}
test_df <- data.frame(actual = data.test$Attrition_Flag, pred = NA)
test_df$prediction <- predict(prunefit.allp, newdata = data.test, type = "class")
conf_matrix_pruned_tree <- confusionMatrix(as.factor(test_df$prediction), as.factor(test_df$actual), positive = "1")
conf_matrix_pruned_tree
```

```{r}
# Missclassification error rate:
misclassification_error <- sum(conf_matrix_pruned_tree$table[2,1], conf_matrix_pruned_tree$table[1,2]) /
                          sum(conf_matrix_pruned_tree$table)
misclassification_error

```

## Random Forest

```{r}
library(ranger)
```

```{r}
fit.rf <- ranger(Attrition_Flag ~ ., data = data.train, 
                   importance = 'impurity', mtry = 3)
print(fit.rf)
```

```{r}
library(vip)
```

```{r}
(v1 <- vi(fit.rf))
```

```{r}
vip(v1)
```

```{r}
pred <- predict(fit.rf, data = data.test)
test_df <- data.frame(actual = data.test$Attrition_Flag, pred = NA)
test_df$predictions <- pred$predictions
conf_matrix_rf <- confusionMatrix(as.factor(test_df$predictions), as.factor(test_df$actual), positive = "1")
conf_matrix_rf
```

```{r}
library(caret)

recall <- sensitivity(conf_matrix_rf$table, positive = "1")
precision <- precision(conf_matrix_rf$table, positive = "1")
f1_score <- F_meas(conf_matrix_rf$table, positive = "1")

# Print the metrics
print(paste("Recall:", recall))
print(paste("Precision:", precision))
print(paste("F1 Score:", f1_score))
  
```

## Gradient Boosting

```{r}
library(xgboost)
library(Matrix)
```

```{r}
# Transform the predictor matrix using dummy (or indicator or one-hot) encoding 
matrix_predictors.train <- 
  as.matrix(sparse.model.matrix(Attrition_Flag ~., data = data.train))[, -1]
matrix_predictors.test <- 
  as.matrix(sparse.model.matrix(Attrition_Flag ~., data = data.test))[, -1]
```

```{r}
# Train dataset
pred.train.gbm <- data.matrix(matrix_predictors.train) # predictors only
#convert factor to numeric
data.train.gbm <- as.numeric(as.character(data.train$Attrition_Flag)) 
dtrain <- xgb.DMatrix(data = pred.train.gbm, label = data.train.gbm)
# Test dataset
pred.test.gbm <- data.matrix(matrix_predictors.test) # predictors only
 #convert factor to numeric
data.test.gbm <- as.numeric(as.character(data.test$Attrition_Flag))
dtest <- xgb.DMatrix(data = pred.test.gbm, label = data.test.gbm)
```

```{r}
watchlist <- list(train = dtrain, test = dtest)
param <- list(max_depth = 2, eta = 1, nthread = 2,
              objective = "binary:logistic", eval_metric = "auc")
```

```{r}
model.xgb <- xgb.train(param, dtrain, nrounds = 7, watchlist)
```

```{r}
pred.y.train <- predict(model.xgb, pred.train.gbm)
prediction.train <- as.numeric(pred.y.train > 0.5)
# Measure prediction accuracy on train data
(tab<-table(data.train.gbm, prediction.train))
```

```{r}
sum(diag(tab))/sum(tab)
```

```{r}
threshold <- 0.5 # This threshold can be adjusted
pred.y = predict(model.xgb, pred.test.gbm)
prediction <- as.numeric(pred.y > threshold) # Convert probabilities to binary predictions

# Now, create the test data frame
test_df <- data.frame(actual = data.test$Attrition_Flag, prediction = prediction)

# Convert both actual and predicted to factors assuming '1' is the positive class
test_df$actual <- as.factor(test_df$actual)
test_df$prediction <- as.factor(test_df$prediction)

# Recreate the confusion matrix
xg.conf_matrix <- confusionMatrix(test_df$prediction, test_df$actual, positive = "1")
print(xg.conf_matrix)

```

```{r}
recall <- sensitivity(xg.conf_matrix$table, positive = "1")

# Calculate precision (positive predictive value)
precision <- posPredValue(xg.conf_matrix$table, positive = "1")

# Calculate F1 score
f1_score <- (2 * precision * recall) / (precision + recall)

# Print the metrics
print(paste("Recall:", recall))
print(paste("Precision:", precision))
print(paste("F1 Score:", f1_score))
```

## SUMMARY AND CONCLUSION

## REFERENCES

\[1\] Rico-Poveda, C.A., & Galpin, I. (2020). Forecasting Credit Card Attrition using Machine Learning Models. ICAI Workshops.

\[2\] Mourtas, S. D., Katsikis, V. N., & Sahas, R. (2023). Credit Card Attrition Classification Through Neuronets. In P. Stanimorovic, A. A. Stupina, E. Semenkin, & I. V. Kovalev (Eds.), Hybrid Methods of Modeling and Optimization in Complex Systems, vol 1. European Proceedings of Computers and Technology (pp. 86-93). European Publisher.
